{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juan026/EVA3D/blob/main/ComputerGraphics_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "#EVA3D: Compositional 3D Human Generation from 2D Image Collections\n",
        "\n",
        "*Hong, F., Chen, Z., Lan, Y., Pan, L., & Liu, Z. (2022). Eva3d: Compositional 3d human generation from 2d image collections. arXiv preprint arXiv:2210.04888.*\n",
        "\n",
        "Juan Antonio Del Hoyo Ontiveros\n",
        "\n",
        "En este se realiza un revisión y adaptación del código con el fin de evaluarlo.\n",
        "Este articulo propone un modelo de tipo red generativa antagónica GAN el cual se entrenó a partir de imágenes 2D para crear lo que se conoce como inversión de gráficos, es decir, pasar de representación 2D a 3D. En el método propuesto los autores aplican una división del cuerpo humano en partes locales,  de esta forma pueden enfocar el aprendizaje en las distintas áreas donde se identifican las articulaciones del cuerpo humano. Finalmente, se logra representar las partes articuladas de manera más precisa.\n",
        "\n",
        "\n",
        "Este demo utiliza el modelo pre-entrenado en la base de datos DeepFashion.\n",
        "\n",
        "\n",
        "Enlaces:\n",
        "\n",
        "Original Github Repo: https://github.com/hongfz16/EVA3D\n",
        "\n",
        "Artículo arXiv Link: https://arxiv.org/abs/2210.04888\n"
      ],
      "metadata": {
        "id": "dZ8b7nDOoy1-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gj9jUt7nZMBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Code used for Computer Graphics Project \n",
        "# Setup Everything\n",
        "\n",
        "# Importamos la copia del repositorio e instalamos todas las librerias requeridas por el proyecto\n",
        "!nvidia-smi\n",
        "!git clone https://github.com/juan026/EVA3D.git\n",
        "\n",
        "!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "version_str=\"\".join([\n",
        "    f\"py3{sys.version_info.minor}_cu\",\n",
        "    torch.version.cuda.replace(\".\",\"\"),\n",
        "    f\"_pyt{pyt_version_str}\"\n",
        "])\n",
        "!pip install fvcore iopath\n",
        "!pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "!pip install -r EVA3D/requirements.txt"
      ],
      "metadata": {
        "id": "6cDCtHPy8z39",
        "outputId": "8d4af473-0ab9-4bcb-eefc-a0a8d4f743a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 27 06:29:20 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Cloning into 'EVA3D'...\n",
            "remote: Enumerating objects: 217, done.\u001b[K\n",
            "remote: Counting objects: 100% (217/217), done.\u001b[K\n",
            "remote: Compressing objects: 100% (156/156), done.\u001b[K\n",
            "remote: Total 217 (delta 100), reused 151 (delta 56), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (217/217), 25.37 MiB | 31.38 MiB/s, done.\n",
            "Resolving deltas: 100% (100/100), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Collecting torch==1.11.0+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp39-cp39-linux_x86_64.whl (1637.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 GB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.12.0+cu113\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.12.0%2Bcu113-cp39-cp39-linux_x86_64.whl (22.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.11.0\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.11.0%2Bcu113-cp39-cp39-linux_x86_64.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.11.0+cu113) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.12.0+cu113) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.12.0+cu113) (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision==0.12.0+cu113) (2.27.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.12.0+cu113) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.12.0+cu113) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.12.0+cu113) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.12.0+cu113) (2.0.12)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.1+cu118\n",
            "    Uninstalling torchvision-0.15.1+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.1+cu118\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.0.1+cu118\n",
            "    Uninstalling torchaudio-2.0.1+cu118:\n",
            "      Successfully uninstalled torchaudio-2.0.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.11.0+cu113 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.11.0+cu113 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.11.0+cu113 torchaudio-0.11.0+cu113 torchvision-0.12.0+cu113\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from fvcore) (1.22.4)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from fvcore) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from fvcore) (4.65.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.9/dist-packages (from fvcore) (2.3.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from fvcore) (8.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from fvcore) (0.8.10)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.9/dist-packages (from iopath) (4.5.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61429 sha256=8bdcb9dbb06544d10f2bc700c9942414b7563e4d4503d7d24748932ff2c41505\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/42/02/66178d16e5c44dc26d309931834956baeda371956e86fbd876\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=3044c35f686f49c6ac197850539e2b8027c17b87a1ad6908e40006144fce2449\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/13/6d/441d8f2af76ee6d2a3e67eebb1d0c556fefcee0a8b32266a8e\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.7.0 yacs-0.1.8\n",
            "Looking in links: https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py39_cu113_pyt1110/download.html\n",
            "Collecting pytorch3d\n",
            "  Downloading https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py39_cu113_pyt1110/pytorch3d-0.7.2-cp39-cp39-linux_x86_64.whl (19.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fvcore in /usr/local/lib/python3.9/dist-packages (from pytorch3d) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.9/dist-packages (from pytorch3d) (0.1.10)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from fvcore->pytorch3d) (0.8.10)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from fvcore->pytorch3d) (8.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from fvcore->pytorch3d) (4.65.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.9/dist-packages (from fvcore->pytorch3d) (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from fvcore->pytorch3d) (1.22.4)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.9/dist-packages (from fvcore->pytorch3d) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from fvcore->pytorch3d) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from iopath->pytorch3d) (4.5.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.9/dist-packages (from iopath->pytorch3d) (2.7.0)\n",
            "Installing collected packages: pytorch3d\n",
            "Successfully installed pytorch3d-0.7.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting chumpy==0.70\n",
            "  Downloading chumpy-0.70.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting imageio==2.16.1\n",
            "  Downloading imageio-2.16.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib==3.5.1\n",
            "  Downloading matplotlib-3.5.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.21.2\n",
            "  Downloading numpy-1.21.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python==4.5.5.64\n",
            "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow==9.0.1\n",
            "  Downloading Pillow-9.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-image==0.19.2\n",
            "  Downloading scikit_image-0.19.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.0.2\n",
            "  Downloading scikit_learn-1.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-video==1.1.11\n",
            "  Downloading scikit_video-1.1.11-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.8.0\n",
            "  Downloading scipy-1.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smplx==0.1.28\n",
            "  Downloading smplx-0.1.28-py3-none-any.whl (29 kB)\n",
            "Collecting trimesh==3.10.7\n",
            "  Downloading trimesh-3.10.7-py3-none-any.whl (642 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m642.1/642.1 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lmdb\n",
            "  Downloading lmdb-1.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.5/298.5 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from -r EVA3D/requirements.txt (line 15)) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from -r EVA3D/requirements.txt (line 16)) (4.65.0)\n",
            "Collecting configargparse\n",
            "  Downloading ConfigArgParse-1.5.3-py3-none-any.whl (20 kB)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: imageio_ffmpeg in /usr/local/lib/python3.9/dist-packages (from -r EVA3D/requirements.txt (line 19)) (0.4.8)\n",
            "Collecting pytorch_fid\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from chumpy==0.70->-r EVA3D/requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.1->-r EVA3D/requirements.txt (line 3)) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.1->-r EVA3D/requirements.txt (line 3)) (23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.1->-r EVA3D/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.1->-r EVA3D/requirements.txt (line 3)) (4.39.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.1->-r EVA3D/requirements.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib==3.5.1->-r EVA3D/requirements.txt (line 3)) (3.0.9)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image==0.19.2->-r EVA3D/requirements.txt (line 7)) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image==0.19.2->-r EVA3D/requirements.txt (line 7)) (3.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image==0.19.2->-r EVA3D/requirements.txt (line 7)) (2023.4.12)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.0.2->-r EVA3D/requirements.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn==1.0.2->-r EVA3D/requirements.txt (line 8)) (3.1.0)\n",
            "Requirement already satisfied: torch>=1.0.1.post2 in /usr/local/lib/python3.9/dist-packages (from smplx==0.1.28->-r EVA3D/requirements.txt (line 11)) (1.11.0+cu113)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->-r EVA3D/requirements.txt (line 15)) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->-r EVA3D/requirements.txt (line 15)) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->-r EVA3D/requirements.txt (line 15)) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->-r EVA3D/requirements.txt (line 15)) (1.26.15)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from pytorch_fid->-r EVA3D/requirements.txt (line 20)) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.0.1.post2->smplx==0.1.28->-r EVA3D/requirements.txt (line 11)) (4.5.0)\n",
            "Building wheels for collected packages: chumpy\n",
            "  Building wheel for chumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chumpy: filename=chumpy-0.70-py3-none-any.whl size=58282 sha256=fc1848774d4e10b028be4038e027d01c6407e98051b6ca2aae163b6b45536c04\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/b5/d3/bbff0d638d797944856371a4ee326f9ffb1829083a383bba77\n",
            "Successfully built chumpy\n",
            "Installing collected packages: ninja, lmdb, pillow, numpy, munch, configargparse, trimesh, smplx, scipy, opencv-python, matplotlib, imageio, scikit-video, scikit-learn, scikit-image, pytorch_fid, chumpy\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.7.0.72\n",
            "    Uninstalling opencv-python-4.7.0.72:\n",
            "      Successfully uninstalled opencv-python-4.7.0.72\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.25.1\n",
            "    Uninstalling imageio-2.25.1:\n",
            "      Successfully uninstalled imageio-2.25.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.19.3\n",
            "    Uninstalling scikit-image-0.19.3:\n",
            "      Successfully uninstalled scikit-image-0.19.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.11.0+cu113 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.21.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chumpy-0.70 configargparse-1.5.3 imageio-2.16.1 lmdb-1.4.1 matplotlib-3.5.1 munch-2.5.0 ninja-1.11.1 numpy-1.21.2 opencv-python-4.5.5.64 pillow-9.0.1 pytorch_fid-0.3.0 scikit-image-0.19.2 scikit-learn-1.0.2 scikit-video-1.1.11 scipy-1.8.0 smplx-0.1.28 trimesh-3.10.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Train a new model using deepfashion dataset\n",
        "%cd EVA3D\n",
        "!python train_deepfashion.py --batch 6 --chunk 1 --expname train_deepfashion_512x256 --dataset_path datasets/DeepFashion --depth 5 --width 128 --style_dim 128 --renderer_spatial_output_dim 512 256 --input_ch_views 3 --white_bg --r1 300 --voxhuman_name eva3d_deepfashion --random_flip --eikonal_lambda 0.5 --small_aug --iter 1000 --adjust_gamma --gamma_lb 20 --min_surf_lambda 1.5 --deltasdf --gaussian_weighted_sampler --sampler_std 15 --N_samples 14\n"
      ],
      "metadata": {
        "id": "1DQ4xgniTz5Y",
        "outputId": "5f572206-f3fa-4eca-ba39-915f6f39de61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/EVA3D\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download Models\n",
        "\n",
        "# Se descargan los modelos preentrenados \n",
        "%cd EVA3D\n",
        "from download_models import download_pretrained_models\n",
        "download_pretrained_models()"
      ],
      "metadata": {
        "id": "8HtVIDlp3ldz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bGbOgk-h4_7M"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iy151ysWxMO"
      },
      "source": [
        "Register and download SMPL models [here](https://smpl.is.tue.mpg.de/). Put the downloaded models in the folder smpl_models. Only the neutral one is needed. The folder structure should look like\n",
        "\n",
        "```\n",
        "./\n",
        "├── ...\n",
        "└── smpl_models/\n",
        "    ├── smpl/\n",
        "        └── SMPL_NEUTRAL.pkl\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download SMPL NEUTRAL model\n",
        "!ls\n",
        "# Descagamos el modelo para la generación de cuerpos humanos en 3D\n",
        "!mkdir smpl_models\n",
        "%cd smpl_models\n",
        "!mkdir smpl\n",
        "%cd smpl\n",
        "!ls\n",
        "!gdown 1DTiAXbVnCRopZ-LObAqKnT-9rv-aySc5\n",
        "!ls"
      ],
      "metadata": {
        "id": "-hhNZp3s_lFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download dataset for training\n",
        "%cd ../..\n",
        "!ls\n",
        "# Se descarga el conjunto de datos Deep Fashion\n",
        "!python download_datasets.py"
      ],
      "metadata": {
        "id": "-IIxFWdn7ocu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title Start the Genenration!\n",
        "# Ejecutamos la inferencia por defecto\n",
        "!python generation_demo.py --batch 1 --chunk 1 --expname 512x256_deepfashion --dataset_path demodataset --depth 5 --width 128 --style_dim 128 --renderer_spatial_output_dim 512 256 --input_ch_views 3 --white_bg --voxhuman_name eva3d_deepfashion --deltasdf --N_samples 28 --ckpt 420000 --identities 1 --truncation_ratio 0.5\n",
        "from IPython.display import Image\n",
        "Image('evaluations/512x256_deepfashion/iter_0420000/random_angles/images_paper_fig/0000000.png')"
      ],
      "metadata": {
        "id": "aMSFMTb5UOE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define images for evaluation\n",
        "import os\n",
        "# define images for evaluation\n",
        "# Se definen las rutas con las imagenes de ejemplos \n",
        "# seleccionados para evaluar el modelo\n",
        "root_dataset = \"/content/EVA3D/datasets/DeepFashion/images/\"\n",
        "\n",
        "testing_images= [\"MEN-Jackets_Vests-id_00005346-01_4_full.png\",\n",
        "                 \"WOMEN-Dresses-id_00006993-03_7_additional.png\",\n",
        "                 \"WOMEN-Blouses_Shirts-id_00001722-07_7_additional.png\"]\n",
        "\n",
        "\n",
        "img_testing1 = os.path.join(root_dataset, testing_images[0])\n",
        "img_testing2 = os.path.join(root_dataset, testing_images[1])\n",
        "img_testing3 = os.path.join(root_dataset, testing_images[2])"
      ],
      "metadata": {
        "id": "0CKkRC9iCmvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define code for transformation\n",
        "\n",
        "# Se importan las librerias de OpenCV para aplicar operaciones de \n",
        "# transformaciones a las imágenes.\n",
        "# Run transformations\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QAZTzN7HCq1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Transformation: Translation\n",
        "# Translation\n",
        "# Se aplica la transformación de traslación en los ejes X,Y con 200 y 150 \n",
        "# pixeles respectivamente.\n",
        "image = cv2.imread(img_testing1)\n",
        "ancho = image.shape[1] #columnas\n",
        "alto = image.shape[0] # filas\n",
        "\n",
        "M = np.float32([[1, 0,200],\n",
        "                [0, 1,150]])\n",
        "imageOut = cv2.warpAffine(image,M,(ancho,alto))\n",
        "print('Input Image')\n",
        "cv2_imshow(image)\n",
        "print('Output Image')\n",
        "cv2_imshow(imageOut)\n",
        "cv2.waitKey(0)\n",
        "# Se guarda la imagen para su posterior inferencia\n",
        "# en el modelo.\n",
        "output_img_path = img_testing1[:-4]+\"__translation.png\"\n",
        "print(output_img_path)\n",
        "cv2.imwrite(output_img_path, imageOut)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# save basename image to file for inference\n",
        "with open(\"file_test1.txt\", \"w\") as ft1:\n",
        "  ft1.write(os.path.basename(output_img_path))"
      ],
      "metadata": {
        "id": "KeQQjk4oRnzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run inference: Translation\n",
        "# Ejecutamos la inferencia en la imagen anterior\n",
        "!python generation_demo.py --batch 1 --chunk 1 --expname 512x256_deepfashion --dataset_path /content/EVA3D/datasets/DeepFashion --depth 5 --width 128 --style_dim 128 --renderer_spatial_output_dim 512 256 --input_ch_views 3 --white_bg --voxhuman_name eva3d_deepfashion --deltasdf --N_samples 28 --ckpt 420000 --identities 1 --truncation_ratio 0.5 --testing_list /content/EVA3D/file_test1.txt\n",
        "from IPython.display import Image\n",
        "Image('evaluations/512x256_deepfashion/iter_0420000/random_angles/images_paper_fig/0000000.png')"
      ],
      "metadata": {
        "id": "ys1OzozJXkfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Transformation: Rotation\n",
        "# Rotation\n",
        "# Se aplica la transformación de rotación usando como eje de rotación \n",
        "# el centro dividiendo por 2 su tamaño, después se rota 30 grados sobre el eje\n",
        "# y no se aplica ningún escalamiento.\n",
        "# pixeles respectivamente.\n",
        "image = cv2.imread(img_testing2)\n",
        "ancho = image.shape[1] #columnas\n",
        "alto = image.shape[0] # filas\n",
        "# Rotación\n",
        "M = cv2.getRotationMatrix2D((ancho//2,alto//2),30,1)\n",
        "imageOut = cv2.warpAffine(image,M,(ancho,alto))\n",
        "print('Input Image')\n",
        "cv2_imshow(image)\n",
        "print('Output Image')\n",
        "cv2_imshow(imageOut)\n",
        "# Se guarda la imagen para su posterior inferencia\n",
        "# en el modelo.\n",
        "output_img_path = img_testing2[:-4]+\"__rotation.png\"\n",
        "print(output_img_path)\n",
        "cv2.imwrite(output_img_path, imageOut)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# save basename image to file for inference\n",
        "with open(\"file_test1.txt\", \"w\") as ft1:\n",
        "  ft1.write(os.path.basename(output_img_path))"
      ],
      "metadata": {
        "id": "BJFpKzLZSRwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run inference: Rotation\n",
        "!python generation_demo.py --batch 1 --chunk 1 --expname 512x256_deepfashion --dataset_path /content/EVA3D/datasets/DeepFashion --depth 5 --width 128 --style_dim 128 --renderer_spatial_output_dim 512 256 --input_ch_views 3 --white_bg --voxhuman_name eva3d_deepfashion --deltasdf --N_samples 28 --ckpt 420000 --identities 1 --truncation_ratio 0.5 --testing_list /content/EVA3D/file_test1.txt\n",
        "from IPython.display import Image\n",
        "Image('evaluations/512x256_deepfashion/iter_0420000/random_angles/images_paper_fig/0000000.png')"
      ],
      "metadata": {
        "id": "0YHXRC0hSwa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Transformation: Scale\n",
        "image = cv2.imread(img_testing3)\n",
        "# Scale\n",
        "# Se aplica la transformación de escalamiento en tamaño\n",
        "# de 650x650 pixeles.\n",
        "# y no se aplica ningún escalamiento.\n",
        "imageOut = cv2.resize(image,(650,650), interpolation=cv2.INTER_CUBIC)\n",
        "print('Input Image')\n",
        "cv2_imshow(image)\n",
        "print('Output Image')\n",
        "cv2_imshow(imageOut)\n",
        "output_img_path = img_testing3[:-4]+\"__scale.png\"\n",
        "print(output_img_path)\n",
        "cv2.imwrite(output_img_path, imageOut)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "# Se guarda la imagen para su posterior inferencia\n",
        "# en el modelo.\n",
        "# save basename image to file for inference\n",
        "with open(\"file_test1.txt\", \"w\") as ft1:\n",
        "  ft1.write(os.path.basename(output_img_path))"
      ],
      "metadata": {
        "id": "gM3HbyclTueR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run inference: Scale\n",
        "!python generation_demo.py --batch 1 --chunk 1 --expname 512x256_deepfashion --dataset_path /content/EVA3D/datasets/DeepFashion --depth 5 --width 128 --style_dim 128 --renderer_spatial_output_dim 512 256 --input_ch_views 3 --white_bg --voxhuman_name eva3d_deepfashion --deltasdf --N_samples 28 --ckpt 420000 --identities 1 --truncation_ratio 0.5 --testing_list /content/EVA3D/file_test1.txt\n",
        "from IPython.display import Image\n",
        "Image('evaluations/512x256_deepfashion/iter_0420000/random_angles/images_paper_fig/0000000.png')"
      ],
      "metadata": {
        "id": "EUMnipDVXKzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusiones\n",
        "\n",
        "Se evalúa aplicando inferencias en el modelo propuesto por los autores del artículo.\n",
        "\n",
        "Se realizaron las siguientes transformaciones: Rotación, escalamiento y traslación en las imágenes.\n",
        "\n",
        "Las salidas demuestran que el modelo es capaz de recrear las representaciones 3D\n",
        "a partir de las observaciones 2D.\n",
        "\n",
        "Se requiere realizar más experimentación en las evaluaciones, cambio de parámetros con el fin de mejorar los resultados obtenidos.\n"
      ],
      "metadata": {
        "id": "iKNr45GKXoS7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wIUYM9KlZEha"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}